{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Group-1**\n",
    "\n",
    "**Title:** Classification of Doremon cartoon characters from a custom Image dataset using a CNN model.\n",
    "\n",
    "**Team members:**\n",
    "Santosh Reddy Edulapalle - A20501739\n",
    "Venkata Siva Rupesh Akurati - A20501754\n",
    "Jack Harrison Mohr -A20503445\n",
    "\n",
    "**This is our .ipynb file for the project. We are going to code everything in this file.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Image dataset:** We are using OpenCV to read the video and capture image with rate of 1 frame per second.\n",
    "\n",
    "**ImageSS** This function takes in path of the video and uses OpenCV to read each frame and captures the images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#importing cv2 from OpenCV\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "def ImageSS(videoPath):\n",
    "\n",
    "    videoObject = cv2.VideoCapture(videoPath)\n",
    "    frameNumber = 3000\n",
    "\n",
    "    # checks whether frames were extracted\n",
    "    boolean = 1\n",
    "    start = datetime.now()\n",
    "    try:\n",
    "        while boolean:\n",
    "           # cv2.waitKey(10) {doesnt reduce fps}\n",
    "            boolean, image = videoObject.read()\n",
    "            cv2.imwrite(\"frame%d.jpg\" %frameNumber, image)\n",
    "            frameNumber += 1\n",
    "    #exception handling\n",
    "    except:\n",
    "        print(\"All the frames are read!\")\n",
    "    finally:\n",
    "        end = datetime.now()\n",
    "    #calculating execution time.\n",
    "    executionTime = (end - start).total_seconds() * 10**3\n",
    "    print(f\"The execution time of above program is : {executionTime:.03f}ms\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below cell is commented to prevent it from accidental running.Uncomment it to use the program to capture video frames."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#ImageSS(\"/Users/santosh/Desktop/doremon6.mp4\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**generate_neg_description_txt_file** This function runs over the negative images folder creates a new text tile with all the names in negative image folder + negative tag attached to it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#Creating our own cascade classifier from scratch.\n",
    "# we are going to train the classifier with our own doremon data.\n",
    "\n",
    "def generate_neg_description_txt_file():\n",
    "    with open('negative.txt','w') as f:\n",
    "        for imageName in os.listdir('negative'):\n",
    "            f.write('negative/' + imageName + '\\n')\n",
    "generate_neg_description_txt_file()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "negatives.txt is relatively easy to do. But for positives.txt, we need to manually upload the frame of the face for each image. To help with it, openCV has annotations app which is only available on version 3x.\n",
    " We installed openCV 3.4.16 to use its annotations functions. For the rest of the project, we will be using openCV latest version.\n",
    "Having had so many troubles with openCV 3.4.16 on my mac, and spending one full day on debugging, I decided to move on to a windows PC and finish the annotation process. I will be transferring the trained model, related files ( annotations.txt) to this mac for further project build.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of videos: 1\n",
      "attempting to detect Doremon in 'Doremon1.mp4'\n",
      "number of videos: 1\n",
      "attempting to detect Nobita in 'Doremon1.mp4'\n",
      "number of videos: 1\n",
      "attempting to detect Shizuka in 'Doremon1.mp4'\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#changes yet to make.\n",
    "import numpy as np\n",
    "\n",
    "# settings\n",
    "videopath = '/Users/santosh/Desktop/dorVid/'\n",
    "exclusion = {\n",
    "    '.DS_Store'\n",
    "}\n",
    "\n",
    "# gets the import location for videos (dataset).\n",
    "def get_dataset(videopath=videopath):\n",
    "    videos = os.listdir(os.path.dirname(videopath))\n",
    "    for item in videos:\n",
    "        if item in exclusion:\n",
    "            videos.remove(item)\n",
    "    return videos\n",
    "\n",
    "# detect character by using a custom trained haar cascade for each character.\n",
    "def detect(character, video, show_video=True):\n",
    "    cap = cv2.VideoCapture(videopath + video)\n",
    "    Dor_face_cascade = cv2.CascadeClassifier('cascadeAll.xml')\n",
    "    results_path = os.path.join('results/' + \"Dor_char\")\n",
    "\n",
    "    # make a folder in results for our recognised faces.\n",
    "    if not os.path.exists(results_path) and character['save'] == True:\n",
    "        os.mkdir(results_path)\n",
    "\n",
    "    while(1):\n",
    "        # grab a frame.\n",
    "        ret, frame = cap.read()\n",
    "        faces = None\n",
    "\n",
    "\n",
    "        if character['name'] == \"Doremon\":\n",
    "            # detect faces in our image.\n",
    "            # try only with frame, no extra parameters.\n",
    "            faces = Dor_face_cascade.detectMultiScale(frame,\n",
    "                                                  scaleFactor=1.05,\n",
    "                                                  minNeighbors=50,\n",
    "                                                  minSize=(24, 24),\n",
    "                                                  flags=cv2.CASCADE_SCALE_IMAGE\n",
    "                                                  )\n",
    "        elif character['name'] == \"Nobita\":\n",
    "            faces = Dor_face_cascade.detectMultiScale(frame,\n",
    "                                                  scaleFactor=1.05,\n",
    "                                                  minNeighbors=50,\n",
    "                                                  minSize=(24, 24),\n",
    "                                                  flags=cv2.CASCADE_SCALE_IMAGE\n",
    "                                                  )\n",
    "        elif character['name'] == \"Shizuka\":\n",
    "            faces = Dor_face_cascade.detectMultiScale(frame,\n",
    "                                                      scaleFactor=1.05,\n",
    "                                                      minNeighbors=50,\n",
    "                                                      minSize=(24, 24),\n",
    "                                                      flags=cv2.CASCADE_SCALE_IMAGE\n",
    "                                                      )\n",
    "\n",
    "        # loop over detected faces.\n",
    "        for (x, y, w, h) in faces:\n",
    "            # setup region of interest (ROI) for the captured face.\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            frame_number = str(int(cap.get(cv2.CAP_PROP_POS_FRAMES)))\n",
    "\n",
    "            # write detected face to disk.\n",
    "            if character['save'] == True:\n",
    "                cv2.imwrite(results_path + '/' + \"character\" + '_frame_' + frame_number + '.png', roi)\n",
    "\n",
    "            if show_video is True:\n",
    "                # display detection box for visual purposes.\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), character['detect_color'], 2)\n",
    "                cv2.putText(frame, character['name'], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2)\n",
    "            else:\n",
    "                print('detected face @ frame ' + frame_number)\n",
    "\n",
    "        if show_video is True:\n",
    "            # display our image.\n",
    "            try:\n",
    "                cv2.imshow('frame', frame)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            # quit or (next video) on esc.\n",
    "            esc = cv2.waitKey(30) & 0xff\n",
    "            if esc == 27:\n",
    "                break\n",
    "\n",
    "    # destroy & release resources.\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "# process all our videos.\n",
    "def process(character):\n",
    "    videos = get_dataset()\n",
    "    print('number of videos: ' + str(len(videos)))\n",
    "\n",
    "    for video in enumerate(videos):\n",
    "        episode = video[1]\n",
    "\n",
    "        # dump frames and save to disk each character.\n",
    "        print('attempting to detect ' + character['name'] +  ' in \\'' + episode + '\\'')\n",
    "\n",
    "        # detect our character.\n",
    "        detect(character, video[1], show_video=True)\n",
    "\n",
    "def main():\n",
    "    # step 1: prepare our results folder.\n",
    "    if not os.path.exists('results'):\n",
    "        os.mkdir('results')\n",
    "\n",
    "    # step 2: process all our videos to detect Tom & Jerry.\n",
    "    characters = [\n",
    "        {\n",
    "            'name':      \"Doremon\",\n",
    "            'detect_color': (26,225,248),\n",
    "            'save':\t\t True,\n",
    "            'cascade':   'doremon.xml'\n",
    "        },\n",
    "        {\n",
    "            'name':      \"Nobita\",\n",
    "            'detect_color': (236,195, 80),\n",
    "            'save':\t\t True,\n",
    "            'cascade':   'nobita.xml'\n",
    "        },\n",
    "        {\n",
    "            'name':      \"Shizuka\",\n",
    "            'detect_color': (255,182,193),\n",
    "            'save':\t\t True,\n",
    "            'cascade':   'shizuka.xml'\n",
    "        }\n",
    "    ]\n",
    "    # process characters...\n",
    "    [process(character) for character in characters]\n",
    "    print('done')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
